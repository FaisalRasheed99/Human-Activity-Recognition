{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_zhnwbmpXVv"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "1aHE00RGufMs",
    "outputId": "19bfe694-8630-4b63-a1cf-d26c8c4488fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jdhOwHm1pXV2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lueh0oJTpXV7"
   },
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LjKuQdEmpXWA"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DiwPaX6kpXWB"
   },
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p30OLk5WpXWF"
   },
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-uo6R9PspXWJ"
   },
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'/content/drive/My Drive/HumanActivityRecognition.zip (Unzipped Files)/HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "llDk4Q_rpXWM"
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'/content/drive/My Drive/HumanActivityRecognition.zip (Unzipped Files)/HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mDH9xj3-pXWP"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 62
    },
    "colab_type": "code",
    "id": "CF0eVkIipXWU",
    "outputId": "abfb98bb-3909-4d99-f946-70e1f9256e93"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kFMi0OVzpXWY"
   },
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IBCTeKWSpXWc",
    "outputId": "c1296104-e4e7-4e7e-e8b1-d79a57d605ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMFZiRgApXWg"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fs10CXGipXWj"
   },
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZJLbDx0ZpXWm"
   },
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "DbUYmD08pXWr",
    "outputId": "45f616eb-380d-442d-bac1-1773db17c55a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "2GnX3fQTpXWv",
    "outputId": "a5c95b77-09fd-4b49-af97-c7673f0a4c03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LqSt8MwcwXrr"
   },
   "source": [
    "# MODEL 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ELEP1lxYpXW0"
   },
   "source": [
    "- Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "mscgLUhjpXW1",
    "outputId": "80b0f0b6-2a8f-42d9-b531-14401d4b16dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 64)                18944     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 19,334\n",
      "Trainable params: 19,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBi2EsBUpXW4"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5mcYEQKvaJv"
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ipHlAWrJpXW7",
    "outputId": "571da699-37af-4954-8892-5c287b9ff3aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 117s 16ms/step - loss: 0.6147 - acc: 0.7507 - val_loss: 0.7555 - val_acc: 0.6420\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.64201, saving model to weights-improvement-01-0.64.hdf5\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 117s 16ms/step - loss: 0.5317 - acc: 0.7965 - val_loss: 0.7065 - val_acc: 0.7391\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.64201 to 0.73906, saving model to weights-improvement-02-0.74.hdf5\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 116s 16ms/step - loss: 0.3763 - acc: 0.8785 - val_loss: 0.4583 - val_acc: 0.8537\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.73906 to 0.85375, saving model to weights-improvement-03-0.85.hdf5\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 117s 16ms/step - loss: 0.3020 - acc: 0.9047 - val_loss: 0.4113 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.85375 to 0.87648, saving model to weights-improvement-04-0.88.hdf5\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 119s 16ms/step - loss: 0.2644 - acc: 0.9159 - val_loss: 0.4080 - val_acc: 0.8823\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.87648 to 0.88225, saving model to weights-improvement-05-0.88.hdf5\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 118s 16ms/step - loss: 0.2472 - acc: 0.9191 - val_loss: 0.4016 - val_acc: 0.8368\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.88225\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 116s 16ms/step - loss: 0.2530 - acc: 0.9185 - val_loss: 0.3475 - val_acc: 0.8856\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.88225 to 0.88565, saving model to weights-improvement-07-0.89.hdf5\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 115s 16ms/step - loss: 0.2014 - acc: 0.9316 - val_loss: 0.4906 - val_acc: 0.8887\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.88565 to 0.88870, saving model to weights-improvement-08-0.89.hdf5\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 115s 16ms/step - loss: 0.2217 - acc: 0.9301 - val_loss: 0.3442 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.88870 to 0.88904, saving model to weights-improvement-09-0.89.hdf5\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 115s 16ms/step - loss: 0.1871 - acc: 0.9396 - val_loss: 0.4651 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.88904\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 115s 16ms/step - loss: 0.1780 - acc: 0.9384 - val_loss: 0.2848 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.88904 to 0.90804, saving model to weights-improvement-11-0.91.hdf5\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 115s 16ms/step - loss: 0.1606 - acc: 0.9400 - val_loss: 0.3469 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.90804 to 0.91313, saving model to weights-improvement-12-0.91.hdf5\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 114s 16ms/step - loss: 0.1608 - acc: 0.9433 - val_loss: 0.2542 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.91313 to 0.92535, saving model to weights-improvement-13-0.93.hdf5\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 115s 16ms/step - loss: 0.1623 - acc: 0.9438 - val_loss: 0.3026 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92535\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 115s 16ms/step - loss: 0.1783 - acc: 0.9410 - val_loss: 0.3336 - val_acc: 0.9033\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92535\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 115s 16ms/step - loss: 0.1622 - acc: 0.9459 - val_loss: 0.3539 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92535\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 119s 16ms/step - loss: 0.1487 - acc: 0.9459 - val_loss: 0.4675 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.92535\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 0.1628 - acc: 0.9426 - val_loss: 0.3716 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.92535\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 0.1642 - acc: 0.9438 - val_loss: 0.4145 - val_acc: 0.9138\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.92535\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 0.1645 - acc: 0.9437 - val_loss: 0.5506 - val_acc: 0.9033\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.92535\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 119s 16ms/step - loss: 0.1571 - acc: 0.9452 - val_loss: 0.4133 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.92535\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 0.1565 - acc: 0.9459 - val_loss: 0.9380 - val_acc: 0.7930\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.92535\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 118s 16ms/step - loss: 0.1909 - acc: 0.9357 - val_loss: 0.3224 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.92535\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 119s 16ms/step - loss: 0.1364 - acc: 0.9502 - val_loss: 0.2943 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.92535\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 118s 16ms/step - loss: 0.1402 - acc: 0.9533 - val_loss: 0.3748 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.92535\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 117s 16ms/step - loss: 0.1799 - acc: 0.9455 - val_loss: 0.4130 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.92535\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 0.1405 - acc: 0.9468 - val_loss: 0.3196 - val_acc: 0.9063\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.92535\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 119s 16ms/step - loss: 0.1648 - acc: 0.9440 - val_loss: 0.2921 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.92535 to 0.92942, saving model to weights-improvement-28-0.93.hdf5\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 119s 16ms/step - loss: 0.1261 - acc: 0.9504 - val_loss: 0.2755 - val_acc: 0.9345\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.92942 to 0.93451, saving model to weights-improvement-29-0.93.hdf5\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 0.1354 - acc: 0.9518 - val_loss: 0.3681 - val_acc: 0.9260\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.93451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd13541048>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs, callbacks=callbacks_list, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "QRshmtgopXXD",
    "outputId": "8ed689c0-ddc4-4330-e1af-16389eb71a61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
      "True                                 ...                                      \n",
      "LAYING                 537        0  ...                   0                 0\n",
      "SITTING                  6      371  ...                   0                 2\n",
      "STANDING                 0       58  ...                   0                 0\n",
      "WALKING                  0        0  ...                  18                17\n",
      "WALKING_DOWNSTAIRS       0        0  ...                 420                 0\n",
      "WALKING_UPSTAIRS         0        0  ...                   0               468\n",
      "\n",
      "[6 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yKyCkJQp-3DP"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"weights-improvement-29-0.93.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BrmtbeYopXXJ",
    "outputId": "c5abdede-639c-4752-b5b7-9390432f33ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 11s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eOlHVyPEpXXM",
    "outputId": "e99b4d25-0567-414b-e0ac-369873f77a82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2754701370232457, 0.9345096708517137]"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hmzOrkq0xBrU"
   },
   "source": [
    "## MODEL 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "CW4kaPd5xAI8",
    "outputId": "2b984d22-8040-4242-d8d0-60b54db50c92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.85 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 64)                18944     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 19,334\n",
      "Trainable params: 19,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model_2 = Sequential()\n",
    "# Configuring the parameters\n",
    "model_2.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model_2.add(Dropout(0.85))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model_2.add(Dense(n_classes, activation='sigmoid'))\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h2uPHoQSxAP9"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o8IFghPixAbv"
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath_2=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint_2 = ModelCheckpoint(filepath_2, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list_2 = [checkpoint_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "czgwAHfuxAh1",
    "outputId": "607f7232-82e1-4da6-b346-01caf7a5d112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 1.3889 - acc: 0.4153 - val_loss: 1.3153 - val_acc: 0.3967\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.39667, saving model to weights-improvement-01-0.40.hdf5\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.1930 - acc: 0.4771 - val_loss: 1.0943 - val_acc: 0.4978\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.39667 to 0.49779, saving model to weights-improvement-02-0.50.hdf5\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.1085 - acc: 0.5140 - val_loss: 1.2079 - val_acc: 0.4890\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.49779\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 0.9784 - acc: 0.5771 - val_loss: 1.1488 - val_acc: 0.5141\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.49779 to 0.51408, saving model to weights-improvement-04-0.51.hdf5\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 0.8613 - acc: 0.6213 - val_loss: 0.8515 - val_acc: 0.6128\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.51408 to 0.61283, saving model to weights-improvement-05-0.61.hdf5\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 119s 16ms/step - loss: 0.8277 - acc: 0.6401 - val_loss: 0.8997 - val_acc: 0.6077\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.61283\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 0.7738 - acc: 0.6449 - val_loss: 0.8020 - val_acc: 0.6142\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.61283 to 0.61418, saving model to weights-improvement-07-0.61.hdf5\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.0650 - acc: 0.5766 - val_loss: 1.1993 - val_acc: 0.4846\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.61418\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 0.7476 - acc: 0.6582 - val_loss: 0.7277 - val_acc: 0.6169\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.61418 to 0.61690, saving model to weights-improvement-09-0.62.hdf5\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 119s 16ms/step - loss: 0.7187 - acc: 0.6726 - val_loss: 0.7794 - val_acc: 0.6345\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.61690 to 0.63454, saving model to weights-improvement-10-0.63.hdf5\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 119s 16ms/step - loss: 0.6860 - acc: 0.6862 - val_loss: 0.7347 - val_acc: 0.6804\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.63454 to 0.68035, saving model to weights-improvement-11-0.68.hdf5\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 119s 16ms/step - loss: 0.6754 - acc: 0.7044 - val_loss: 0.9391 - val_acc: 0.6807\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.68035 to 0.68069, saving model to weights-improvement-12-0.68.hdf5\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 0.6570 - acc: 0.7393 - val_loss: 0.6910 - val_acc: 0.7377\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.68069 to 0.73770, saving model to weights-improvement-13-0.74.hdf5\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 119s 16ms/step - loss: 0.5847 - acc: 0.7647 - val_loss: 0.7774 - val_acc: 0.7465\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.73770 to 0.74652, saving model to weights-improvement-14-0.75.hdf5\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 119s 16ms/step - loss: 0.8019 - acc: 0.7356 - val_loss: 0.9425 - val_acc: 0.7279\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.74652\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 119s 16ms/step - loss: 1.1701 - acc: 0.4735 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.74652\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.74652\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.74652\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.74652\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.74652\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.74652\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.74652\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.74652\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.74652\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.74652\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.74652\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.74652\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 121s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.74652\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 124s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.74652\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 128s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.74652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd1317c710>"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model_2.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs, callbacks=callbacks_list_2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "bRkFGN5YxAZD",
    "outputId": "54b78f29-390a-4208-914f-abed605e9f67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                STANDING  WALKING\n",
      "True                                 \n",
      "LAYING                     0      537\n",
      "SITTING                    0      491\n",
      "STANDING                   0      532\n",
      "WALKING                    0      496\n",
      "WALKING_DOWNSTAIRS         0      420\n",
      "WALKING_UPSTAIRS           1      470\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model_2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8dr1xV-_oVl"
   },
   "outputs": [],
   "source": [
    "model_2.load_weights(\"weights-improvement-14-0.75.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yp_jrOHFxAWv",
    "outputId": "7cdbe33e-1fb2-486d-e09c-b5290b6b8f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 8s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "score_2 = model_2.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NEsAK4zCxAFm",
    "outputId": "ff413488-f88f-461a-ea9f-6115560a2603"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.777425277413131, 0.7465218866644044]"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OiIPlC9Ey6iN"
   },
   "source": [
    "## MODEL 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "avqn7cUTxAAP",
    "outputId": "077d6610-c613-4638-9fe0-32c91c1b7008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 256)               272384    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 273,926\n",
      "Trainable params: 273,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model_3 = Sequential()\n",
    "# Configuring the parameters\n",
    "model_3.add(LSTM(256, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model_3.add(Dropout(0.8))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model_3.add(Dense(n_classes, activation='sigmoid'))\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dupPggUvw_9H"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UtN5cSPKw_4_"
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint_3 = ModelCheckpoint(\"model_3.hdf5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list_3 = [checkpoint_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "khTZzDyTw_1c",
    "outputId": "c4d75b64-db81-420d-a6af-f1b07c3962ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.16831, saving model to model_3.hdf5\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.16831\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.16831\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.16831\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.16831\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 119s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.16831\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.16831\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 121s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.16831\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.16831\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 121s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.16831\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 121s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.16831\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.16831\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.16831\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.16831\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.16831\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 123s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.16831\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 124s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.16831\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.16831\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.16831\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.16831\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.16831\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.16831\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.16831\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.16831\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.16831\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 124s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.16831\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.16831\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.16831\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.16831\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.16831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd12d0e240>"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model_3.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs, callbacks=callbacks_list_3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "bSsFrFSmzFlo",
    "outputId": "57dc1df1-b346-428d-8022-0db754afeb53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                STANDING  WALKING\n",
      "True                                 \n",
      "LAYING                     0      537\n",
      "SITTING                    0      491\n",
      "STANDING                   0      532\n",
      "WALKING                    0      496\n",
      "WALKING_DOWNSTAIRS         0      420\n",
      "WALKING_UPSTAIRS           1      470\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model_3.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0N6KfPi-FdD"
   },
   "outputs": [],
   "source": [
    "model_3.load_weights(\"model_3.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zjCZq7G9zFjk",
    "outputId": "a6632167-7136-4558-882d-c8e2b1634f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 9s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "score_3 = model_3.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "b_-HKG1KzFe4",
    "outputId": "056f453d-273c-40fe-efe6-379dd7f0cc5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7911514966496784, 0.168306752629793]"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C4NAWXB9zPHi"
   },
   "source": [
    "## MODEL 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "colab_type": "code",
    "id": "P7Z00dZszYfO",
    "outputId": "6873c99b-9d41-4934-8432-1fd008549656"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.85 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128, 128)          70656     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 156)               177840    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 156)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 942       \n",
      "=================================================================\n",
      "Total params: 249,438\n",
      "Trainable params: 249,438\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model_4 = Sequential()\n",
    "# Configuring the parameters\n",
    "model_4.add(LSTM(128, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "# Adding a dropout layer\n",
    "model_4.add(Dropout(0.8))\n",
    "# Configuring the parameters\n",
    "model_4.add(LSTM(156, input_shape=(timesteps, input_dim), return_sequences=False))\n",
    "# Adding a dropout layer\n",
    "model_4.add(Dropout(0.85))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model_4.add(Dense(n_classes, activation='sigmoid'))\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "Fd5nntAvzYoh",
    "outputId": "882c65fd-a4f8-4b3c-84c7-7025c786f7b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "model_4.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U7btX9JazZUE"
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint_4 = ModelCheckpoint(\"model_4.hdf5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list_4 = [checkpoint_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "w391WjDezZi5",
    "outputId": "9fd80332-293d-4054-ee62-e8a965c06e53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "7352/7352 [==============================] - 247s 34ms/step - loss: 0.3423 - acc: 0.8560 - val_loss: 0.2285 - val_acc: 0.8931\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89311, saving model to model_4.hdf5\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 244s 33ms/step - loss: 0.2459 - acc: 0.8913 - val_loss: 0.2852 - val_acc: 0.8804\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.89311\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 241s 33ms/step - loss: 0.2382 - acc: 0.8983 - val_loss: 0.2189 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89311 to 0.90527, saving model to model_4.hdf5\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 241s 33ms/step - loss: 0.1691 - acc: 0.9371 - val_loss: 0.1582 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.90527 to 0.95012, saving model to model_4.hdf5\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 241s 33ms/step - loss: 0.1201 - acc: 0.9632 - val_loss: 0.2274 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95012\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 243s 33ms/step - loss: 0.1105 - acc: 0.9691 - val_loss: 0.1151 - val_acc: 0.9654\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.95012 to 0.96545, saving model to model_4.hdf5\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 241s 33ms/step - loss: 0.0780 - acc: 0.9745 - val_loss: 0.1539 - val_acc: 0.9635\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.96545\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 243s 33ms/step - loss: 0.0752 - acc: 0.9756 - val_loss: 0.0951 - val_acc: 0.9687\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.96545 to 0.96873, saving model to model_4.hdf5\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 243s 33ms/step - loss: 0.0707 - acc: 0.9763 - val_loss: 0.0987 - val_acc: 0.9724\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.96873 to 0.97240, saving model to model_4.hdf5\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 242s 33ms/step - loss: 0.0641 - acc: 0.9783 - val_loss: 0.1314 - val_acc: 0.9682\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.97240\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 241s 33ms/step - loss: 0.0689 - acc: 0.9778 - val_loss: 0.1000 - val_acc: 0.9748\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.97240 to 0.97478, saving model to model_4.hdf5\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 242s 33ms/step - loss: 0.0699 - acc: 0.9766 - val_loss: 0.2142 - val_acc: 0.9609\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.97478\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 240s 33ms/step - loss: 0.0648 - acc: 0.9784 - val_loss: 0.1625 - val_acc: 0.9653\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.97478\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 241s 33ms/step - loss: 0.0610 - acc: 0.9787 - val_loss: 0.1759 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.97478\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 241s 33ms/step - loss: 0.0606 - acc: 0.9796 - val_loss: 0.1488 - val_acc: 0.9673\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.97478\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 239s 33ms/step - loss: 0.0806 - acc: 0.9780 - val_loss: 0.1119 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.97478\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 243s 33ms/step - loss: 0.0671 - acc: 0.9783 - val_loss: 0.1221 - val_acc: 0.9722\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.97478\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 246s 33ms/step - loss: 0.0702 - acc: 0.9777 - val_loss: 0.1422 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.97478\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 247s 34ms/step - loss: 0.0607 - acc: 0.9784 - val_loss: 0.1791 - val_acc: 0.9682\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.97478\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 247s 34ms/step - loss: 0.0612 - acc: 0.9788 - val_loss: 0.2451 - val_acc: 0.9624\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.97478\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 247s 34ms/step - loss: 0.0621 - acc: 0.9787 - val_loss: 0.2602 - val_acc: 0.9561\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.97478\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 244s 33ms/step - loss: 0.0672 - acc: 0.9782 - val_loss: 0.1453 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.97478\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 246s 33ms/step - loss: 0.0651 - acc: 0.9785 - val_loss: 0.1492 - val_acc: 0.9722\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.97478\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 243s 33ms/step - loss: 0.0638 - acc: 0.9805 - val_loss: 0.1571 - val_acc: 0.9686\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.97478\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 241s 33ms/step - loss: 0.0558 - acc: 0.9793 - val_loss: 0.1445 - val_acc: 0.9709\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.97478\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 241s 33ms/step - loss: 0.0582 - acc: 0.9793 - val_loss: 0.1625 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.97478\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 242s 33ms/step - loss: 0.0658 - acc: 0.9787 - val_loss: 0.1349 - val_acc: 0.9733\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.97478\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 244s 33ms/step - loss: 0.0647 - acc: 0.9801 - val_loss: 0.1577 - val_acc: 0.9713\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.97478\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 243s 33ms/step - loss: 0.0614 - acc: 0.9792 - val_loss: 0.1363 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.97478\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 243s 33ms/step - loss: 0.0572 - acc: 0.9798 - val_loss: 0.1865 - val_acc: 0.9703\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.97478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f048ef07a20>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model_4.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs, callbacks=callbacks_list_4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "4yeWsUmUzZqh",
    "outputId": "936a8495-021b-4bd4-e41a-07bd779c4678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
      "True                                 ...                                      \n",
      "LAYING                 537        0  ...                   0                 0\n",
      "SITTING                  0      386  ...                   0                 2\n",
      "STANDING                 0       77  ...                   0                 0\n",
      "WALKING                  0        0  ...                  46                 0\n",
      "WALKING_DOWNSTAIRS       0        0  ...                 418                 1\n",
      "WALKING_UPSTAIRS         0       10  ...                  15               444\n",
      "\n",
      "[6 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model_4.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q_mTaUFaVVg2"
   },
   "outputs": [],
   "source": [
    "model_4.load_weights(\"model_4.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4UJBBUAXzZbW",
    "outputId": "7ab1d8e6-a8cd-4fda-8688-ad66de0fa90b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 17s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "score_4 = model_4.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_Thco6CGzYkQ",
    "outputId": "3db173ab-67e8-4c41-d0f2-ffe3b4e785b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10004483527701037, 0.9747766094123625]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u1IBwm2IzcVc"
   },
   "source": [
    "## RESULTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "O5s_wyrCzger",
    "outputId": "35c881c4-926a-432d-9961-25bbe544d5c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------+------------+---------------+\n",
      "| Model | No. of LSTM layers | Batch Size |  Dropouts  | Val. Accuracy |\n",
      "+-------+--------------------+------------+------------+---------------+\n",
      "|   1   |         1          |     64     |    0.5     |     93.45%    |\n",
      "|   2   |         1          |     64     |    0.85    |     74.65%    |\n",
      "|   3   |         1          |    256     |    0.8     |     16.83%    |\n",
      "|   4   |         2          | 128 & 156  | 0.8 & 0.85 |     97.48%    |\n",
      "+-------+--------------------+------------+------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "#http://zetcode.com/python/prettytable/\n",
    "from prettytable import PrettyTable\n",
    "    \n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Model\", \"No. of LSTM layers\", \"Batch Size\", \"Dropouts\", \"Val. Accuracy\"]\n",
    "x.add_row([1, 1, 64, 0.5,  \"93.45%\"])\n",
    "x.add_row([2, 1, 64, 0.85, \"74.65%\"])\n",
    "x.add_row([3, 1, 256, 0.8, \"16.83%\"])\n",
    "x.add_row([4, 2, \"128 & 156\", \"0.8 & 0.85\", \"97.48%\"])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzMqX9u8KKSo"
   },
   "source": [
    "## CONCLUSIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uMHZkjQDpXXO"
   },
   "source": [
    "- TotaL 4 LSTM models with different architectures were made.\n",
    "- 3 of them were having 1 LSTM layers, 1 were having 2 LSTM layers.\n",
    "- Various varying values of Batch Size & Dropouts were used for hyperparameter tuning.\n",
    "- The first model was 1 LSTM layered, having batch size of 64 & dropout of 0.5.\n",
    "- The second model was 1 LSTM layered, having batch size of 64 & dropout of 0.85.\n",
    "- The third model was 1 LSTM layered, having batch size of 256 & dropout of 0.8.\n",
    "- The fourth model was 2 LSTM layered, having batch size of (128 & 156) & dropout of (0.8 & 0.85).\n",
    "- With a simple 2 LSTM layer architecture we got  maximum 97.48% accuracy and a loss of 0.1865\n",
    "- We can further imporve the performace with Hyperparameter tuning"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HAR_LSTM_faisal.rash99@gmail.com_21.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
